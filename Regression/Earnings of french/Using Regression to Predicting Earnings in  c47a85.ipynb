{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting Earnings of French People\n***"},{"metadata":{},"cell_type":"markdown","source":"***Piotr Skalski - 05.11.2017***"},{"metadata":{},"cell_type":"markdown","source":"<img src='http://res.freestockphotos.biz/pictures/8/8163-euro-coins-and-bills-pv.jpg'>"},{"metadata":{},"cell_type":"markdown","source":"## Table of Contents\n***\n* [1. Introduction](#introduction) <br>\n* [2. Importing dataset and data preprocessing](#importing_dataset_and_data_preprocessing) <br>\n   * [2.1. Importing essential libraries](#importing_essential_libraries) <br>\n   * [2.2. Importing datasets](#importing_datasets) <br>\n   * [2.3. Let's summarize the datasets](#lets_summarize_the_dataset) <br>\n   * [2.4. Data preprocessing & feature engineering](#data_preprocessing) <br>\n      * [2.4.1. Salary dataset preprocessing](#salary_dataset_preprocessing) <br>\n      * [2.4.2. Geography dataset preprocessing](#geography_dataset_preprocessing) <br>\n      * [2.4.3. Industry dataset preprocessing](#industry_dataset_preprocessing) <br>\n      * [2.4.4. Merging datasets](#merging_datasets) <br>\n      * [2.4.5. Splitting dataset into training and testset](#splitting_dataset_into_training_and_testset) <br>\n* [3. Prediction](#prediction) <br>\n   * [3.1. Linear Regression](#linear_regression) <br>\n   * [3.2. Random Forest Regressor](#random_forest_regressor) <br>\n   * [3.3. Evaluating the regression model](#evaluating_regression_model) <br>\n***"},{"metadata":{},"cell_type":"markdown","source":"## 1. Introduction\n<a id=\"introduction\"></a>"},{"metadata":{},"cell_type":"markdown","source":"The purpose of this kernel is to create a model that allow for predicting earnings in France, based on some basic information about the employee and where he lives. The analysis carried out here is largely basedo on conclusions from <a href=\"https://www.kaggle.com/skalskip/how-big-is-french-industry-data-visualization\">How big is French Industry? [Data Visualization]</a> [1]. To fully understand the decisions we'll make while creating a model, it is a good idea to read above notebook.\n\nI also note that I am a novice in Machine Learning and Data Science. Thanks in advance for any suggestions and hints. Please share with me your ideas on the features I can use."},{"metadata":{},"cell_type":"markdown","source":"## 2. Importing dataset and data preprocessing\n<a id=\"importing_dataset_and_data_preprocessing\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### 2.1. Importing essential libraries\n<a id=\"importing_essential_libraries\"></a>"},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport geopandas as gpd\nfrom scipy.optimize import curve_fit\nimport seaborn as sns\n\nfrom math import radians, cos, sin, asin, sqrt\n\nfrom mpl_toolkits.basemap import Basemap\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as colors\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2. Importing datasets\n<a id=\"importing_datasets\"></a>"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Datasets\ngeography = pd.read_csv(\"../input/name_geographic_information.csv\")\nindustry = pd.read_csv(\"../input/base_etablissement_par_tranche_effectif.csv\")\nsalary = pd.read_csv(\"../input/net_salary_per_town_categories.csv\")\npopulation = pd.read_csv(\"../input/population.csv\")\n# Geojson for map creations\ndepartments_map = gpd.read_file('../input/departements.geojson')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3. Let's summarize the datasets\n<a id=\"lets_summarize_the_dataset\"></a>"},{"metadata":{"_kg_hide-output":true,"trusted":false},"cell_type":"code","source":"geography.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":false},"cell_type":"code","source":"industry.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":false},"cell_type":"code","source":"salary.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"population.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"scrolled":true,"trusted":false},"cell_type":"code","source":"population.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.4. Data preprocessing & feature engineering\n<a id=\"data_preprocessing\"></a>"},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> As you can see our dataset consists of four separate files, which store different types of information. Unfortunately, the information in these files is often contaminated or incomplete. At this point our task is to clean up the data and merge four files into one consistent DataFrame which can be used to train the model."},{"metadata":{},"cell_type":"markdown","source":"### 2.4.1. Salary dataset preprocessing\n<a id=\"salary_dataset_preprocessing\"></a>"},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> Salary dataset contains key information on the level of earnings of French citizens according to their place of residence, gender, occupation and age. Due to the very unfavorable data structure we will be forced to create new DataFrame and fill it based on properly processed data from salary dataset."},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"salary = salary[salary[\"CODGEO\"].apply(lambda x: str(x).isdigit())]\nsalary[\"CODGEO\"] = salary[\"CODGEO\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"salary.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> Let's save a copy of salary dataset, in case we will need it later. "},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"salary_copy = salary.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> As we have seen in [1] there is a strong connection between sex, age and occupation, and the amount of money earned. Unfortunately, due to the way dataset was build, we can not use all of these attributes at the same time. Firstly, let's look at how the pay varies depending on gender and age."},{"metadata":{"_kg_hide-input":true,"scrolled":false,"trusted":false},"cell_type":"code","source":"age = [\"18-25 years old\", \"26-50 years old\", \">50 years old\"]\nwoman_age = [\"SNHMF1814\", \"SNHMF2614\", \"SNHMF5014\"]\nwoman_salary_age = salary[woman_age].mean().tolist()\nman_age = [\"SNHMH1814\", \"SNHMH2614\", \"SNHMH5014\"]\nman_salary_age = salary[man_age].mean().tolist()\n\ndif_in_prc_age = []\nfor w, m in zip(woman_salary_age, man_salary_age):\n    dif_in_prc_age.append(round(abs(w-m)/m * 100, 2))\n    \ntrace1 = go.Bar(\n    x = age,\n    y = woman_salary_age,\n    name='Women',\n    marker=dict(\n        color='rgba(55, 128, 191, 0.7)',\n        line=dict(\n            color='rgba(55, 128, 191, 1.0)',\n            width=2,\n        )\n    )\n)\ntrace2 = go.Bar(\n    x = age,\n    y = man_salary_age,\n    name='Men',\n    marker=dict(\n        color='rgba(219, 64, 82, 0.7)',\n        line=dict(\n            color='rgba(219, 64, 82, 1.0)',\n            width=2,\n        )\n    )\n)\n\ntrace3 = go.Scatter(\n    x = age,\n    y = dif_in_prc_age,\n    name='Earnings difference',\n    mode = 'lines+markers',\n    yaxis='y2'\n)\n\ndata = [trace1, trace2, trace3]\nlayout = go.Layout(\n    barmode='group',\n    title = 'Age and sex are',\n    width=850,\n    height=500,\n    paper_bgcolor='rgb(244, 238, 225)',\n    plot_bgcolor='rgb(244, 238, 225)',\n    yaxis = dict(\n        title= 'Average earnings [â‚¬/hour]',\n        anchor = 'x',\n        rangemode='tozero'\n    ),\n    xaxis = dict(title= 'Age'),\n    \n    yaxis2=dict(\n        title='Earnings difference',\n        titlefont=dict(\n            color='rgb(148, 103, 189)'\n        ),\n        tickfont=dict(\n            color='rgb(148, 103, 189)'\n        ),\n        overlaying='y',\n        side='right',\n        anchor = 'x',\n        rangemode = 'tozero',\n        dtick = 7.3\n    ),\n    #legend=dict(x=-.1, y=1.2)\n    legend=dict(x=0.72, y=0.05)\n)\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":false},"cell_type":"code","source":"positions = [\"Executive\", \"Middle manager\", \"Employee\", \"Worker\"]\nwoman_positions = [\"SNHMFC14\", \"SNHMFP14\", \"SNHMFE14\", \"SNHMFO14\"]\nwoman_salary_positions = salary[woman_positions].mean().tolist()\nman_positions = [\"SNHMHC14\", \"SNHMHP14\", \"SNHMHE14\", \"SNHMHO14\"]\nman_salary_positions = salary[man_positions].mean().tolist()\n\ndif_in_prc = []\nfor w, m in zip(woman_salary_positions, man_salary_positions):\n    dif_in_prc.append(round(abs(w-m)/m * 100, 2))\n\ntrace1 = go.Bar(\n    x = positions,\n    y = woman_salary_positions,\n    name='Women',\n    marker=dict(\n        color='rgba(55, 128, 191, 0.7)',\n        line=dict(\n            color='rgba(55, 128, 191, 1.0)',\n            width=2,\n        )\n    )\n)\ntrace2 = go.Bar(\n    x = positions,\n    y = man_salary_positions,\n    name='Men',\n    marker=dict(\n        color='rgba(219, 64, 82, 0.7)',\n        line=dict(\n            color='rgba(219, 64, 82, 1.0)',\n            width=2,\n        )\n    )\n)\n\ntrace3 = go.Scatter(\n    x = positions,\n    y = dif_in_prc,\n    name='Earnings difference',\n    mode = 'lines+markers',\n    yaxis='y2'\n)\n\ndata = [trace1, trace2, trace3]\nlayout = go.Layout(\n    barmode='group',\n    title = 'Stereotype is real',\n    width=850,\n    height=500,\n    paper_bgcolor='rgb(244, 238, 225)',\n    plot_bgcolor='rgb(244, 238, 225)',\n    yaxis = dict(\n        title= 'Average earnings [â‚¬/hour]',\n        anchor = 'x',\n        rangemode='tozero'\n    ),\n    xaxis = dict(title= 'Position'),\n    \n    yaxis2=dict(\n        title='Earnings difference',\n        titlefont=dict(\n            color='rgb(148, 103, 189)'\n        ),\n        tickfont=dict(\n            color='rgb(148, 103, 189)'\n        ),\n        overlaying='y',\n        side='right',\n        anchor = 'x',\n        rangemode = 'tozero',\n        dtick = 8\n    ),\n    #legend=dict(x=-.1, y=1.2)\n    legend=dict(x=0.05, y=0.05)\n)\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> Let's create new DataFrame that will separate information for different age groups. DataFrame will have four columns: \"CODGEO\", \"SEX\" (1 - for woman, 2 - for man), \"AGE\" (1 - for age between 18-25 years, 2 - for age between 26-50 years, 3 - for age over 50 years) and \"WAGE\" that will hold mean net salary per hour."},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"row_fields = {}\nrow_fields[\"SNHMFC14\"] = {\"SEX\": 1, \"POSITION\": 4}\nrow_fields[\"SNHMFP14\"] = {\"SEX\": 1, \"POSITION\": 3}\nrow_fields[\"SNHMFE14\"] = {\"SEX\": 1, \"POSITION\": 2}\nrow_fields[\"SNHMFO14\"] = {\"SEX\": 1, \"POSITION\": 1}\nrow_fields[\"SNHMHC14\"] = {\"SEX\": 2, \"POSITION\": 4}\nrow_fields[\"SNHMHP14\"] = {\"SEX\": 2, \"POSITION\": 3}\nrow_fields[\"SNHMHE14\"] = {\"SEX\": 2, \"POSITION\": 2}\nrow_fields[\"SNHMHO14\"] = {\"SEX\": 2, \"POSITION\": 1}\n\nreformatted_salary = []\nfor index, row in salary.iterrows():\n    for key, value in row_fields.items(): \n        row_dict = {}\n        row_dict[\"CODGEO\"] = row[\"CODGEO\"]\n        row_dict[\"SEX\"] = value[\"SEX\"]\n        row_dict[\"POSITION\"] = value[\"POSITION\"]\n        row_dict[\"WAGE\"] = row[key]\n        reformatted_salary.append(row_dict)\n        \nreformatted_salary = pd.DataFrame(reformatted_salary)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE: </b> Let's check if all the operations are done correctly."},{"metadata":{"trusted":false},"cell_type":"code","source":"reformatted_salary.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.4.2. Geography dataset preprocessing\n<a id=\"geography_dataset_preprocessing\"></a>"},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> During our analysis in [1] we have noticed that the average earning in districts close to Paris is definitely higher than in the rest of the country. Similarly, in cities located in the vicinity of provincial towns, the average income is higher than in the rest of the region. Let's create two new features: PARIS_CLOSE with values equal 1 or 0, depending on whether the place is closer or farther than 30 km from the center of Paris; MAJOR_CITY_DISTANCE: which will represent the distance in kilometers from the provincial town. "},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> Unfortunately, some of the data in geography DataFrame is incorrect or incomplete. First we will focus on longitude column. We will convert commas to dots to create a correct number [#1]. Then we will delete the incorrect entries [#2] and empty fields [#3]. Finally, we will switch the column type to float [#4]."},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"# 1\ngeography[\"longitude\"] = geography[\"longitude\"].apply(lambda x: str(x).replace(',','.'))\n# 2\nmask = geography[\"longitude\"] == '-'\ngeography.drop(geography[mask].index, inplace=True)\n# 3\ngeography.dropna(subset = [\"longitude\", \"latitude\"], inplace=True)\n# 4\ngeography[\"longitude\"] = geography[\"longitude\"].astype(float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> Now we will drop duplicates from geography dataset."},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"geography.drop_duplicates(subset=[\"code_insee\"], keep=\"first\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"<b>NOTE:</b> Let's define a auxiliary function that will help us calculate the distance between two points on the map."},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"def distance(lon1, lat1, lon2, lat2):\n    # convert decimal degrees to radians \n    lon1 = radians(lon1)\n    lat1 = radians(lat1)\n    lon2 = radians(lon2)\n    lat2 = radians(lat2)\n    \n    # haversine formula \n    dlon = lon2 - lon1 \n    dlat = lat2 - lat1 \n    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n    c = 2 * asin(sqrt(a)) \n    \n    # Radius of earth in kilometers is 6371\n    km = 6371* c\n    return km\n\ndef distance_bigger_than(limit, lon1, lat1, lon2, lat2):\n    dist = distance(lon1, lat1, lon2, lat2)\n    if dist > limit:\n        return 0\n    else:\n        return 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> Let's create new PARIS_CLOSE feature. "},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"# extracting the coordinates of paris\nparis_lat = geography.loc[geography['nom_commune'] == \"Paris\"].iloc[0][\"latitude\"]\nparis_lon = geography.loc[geography['nom_commune'] == \"Paris\"].iloc[0][\"longitude\"]\n\n# auxiliary list that will hold calculated values of PARIS_CLOSE\ndistances = []\n\n# calculating values of PARIS_CLOSE\nfor index, row in geography.iterrows():\n    distances.append(distance_bigger_than(30, row[\"longitude\"], row[\"latitude\"], paris_lon, paris_lat))\n\n# adding new column to DataFrame\ngeography[\"PARIS_CLOSE\"] = pd.Series(distances, index=geography.index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> Let's create new MAJOR_CITY_DISTANCE feature. "},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"# extracting the coordinates of capitals of French provinces\nmajors =  geography[geography[\"nom_commune\"] == geography[\"chef.lieu_rÃ©gion\"]]\nmajor_lats = majors[\"latitude\"].tolist()\nmajor_lons = majors[\"longitude\"].tolist()\n\n# auxiliary list that will hold calculated values of MAJOR_CITY_DISTANCE\ndistances = []\n\n# calculating values of MAJOR_CITY_DISTANCE\nfor index, row in geography.iterrows():\n    \n    single_distances = []\n    for lat, lon in zip(major_lats, major_lons):\n        single_distances.append(int(distance(row[\"longitude\"], row[\"latitude\"], lon, lat)))\n    \n    distances.append(min(single_distances))\n\n# adding new column to DataFrame\ngeography[\"MAJOR_CITY_DISTANCE\"] = pd.Series(distances, index=geography.index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> Let's merge salary and geography datasets and check if our assumption about the relationship between the distance from big cities and the size of salaries were correct."},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"salary_location = salary.merge(geography, how=\"left\", left_on='CODGEO', right_on=\"code_insee\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"salaries_by_dep = salary_location.groupby(\"numÃ©ro_dÃ©partement\").mean()\ndepartments_map = departments_map.merge(salaries_by_dep, how=\"left\", left_on=\"code\", right_index=True)\ndepartments_map.dropna(subset = [\"longitude\", \"latitude\"], inplace=True)\n\nfig, ax = plt.subplots(1, figsize=(15,14))\nax.set_title('Salary by Departments', size=32, x = 0.25, y=0.90)\nfig.patch.set_facecolor((202/255, 204/255, 206/255))\ndepartments_map.plot(ax=ax, column=\"SNHM14\", cmap=plt.cm.plasma, scheme='fisher_jenks', k=10, legend=True)\nleg = ax.get_legend()\nax.set_axis_off()\nleg.set_bbox_to_anchor((0., 0., 0.2, 0.45))\nleg.set_title(\"Mean net salary\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> The visualization made clear that people living in close proximity to Paris earn on average more than the rest of the French population."},{"metadata":{"_kg_hide-input":true,"trusted":false},"cell_type":"code","source":"trace1 = go.Bar(\n    x = [\"Far [distance > 30km]\", \"Close [distance < 30km]\"],\n    y = salary_location.groupby(\"PARIS_CLOSE\")[\"SNHM14\"].mean().tolist(),\n    name='Distance from Paris',\n    marker=dict(\n        color='rgba(55, 128, 191, 0.7)',\n        line=dict(\n            color='rgba(55, 128, 191, 1.0)',\n            width=2,\n        )\n    )\n)\n\ndata = [trace1]\nlayout = go.Layout(\n    title = 'Distance from Paris',\n    width=850,\n    height=500,\n    paper_bgcolor='rgb(202, 204, 206)',\n    plot_bgcolor='rgb(202, 204, 206)',\n    yaxis = dict(\n        title= 'Average earnings [â‚¬/hour]',\n        anchor = 'x',\n        rangemode='tozero'\n    ),\n    xaxis = dict(title= 'Distance from Paris')\n)\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(16,10))\nsns.set_style(\"whitegrid\")\nplt.title('Distance from closest major city', fontsize=20, fontweight='bold', y=1.05,)\nplt.xlabel('Distance from closest major city [km]', fontsize=15)\nplt.ylabel('Average earnings [â‚¬/hour]', fontsize=15)\n\nyears = salary_location[\"MAJOR_CITY_DISTANCE\"].values\nmemory = salary_location[\"SNHM14\"].values\n\nplt.scatter(years, memory, edgecolors='black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.4.3. Industry dataset preprocessing\n<a id=\"industry_dataset_preprocessing\"></a>"},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> Similarly as in the case of a dataset describing wage, we are going to switch \"CODGEO\" column type from object (string) to int, but first we need to get rid of incorrect rows. Some of rows contain non numeric characters. We will select only those values that can be transformed into numbers."},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"industry = industry[industry[\"CODGEO\"].apply(lambda x: str(x).isdigit())]\nindustry[\"CODGEO\"] = industry[\"CODGEO\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> The criteria for defining the size of a business differ from country to country. According to the European Commission, we can divide enterprises info five categories based on number of employees: Micro < 10, Small < 50, Medium < 250, Large < 1000 and Enterprise > 1000. Let's create new features that will be closer to representing those oficial categories. We will also create columns that will represent percentage of total number of businesses that is represented by each category.\n\nWe will ignore 'E14TS0ND' column becouse we don't know enything concrete about those firms."},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"industry['MICRO'] = industry['E14TS1'] + industry['E14TS6']\nindustry['SMALL'] = industry['E14TS10'] + industry['E14TS20']\nindustry['MEDIUM'] = industry['E14TS50'] + industry['E14TS100']\nindustry['LARGE'] = industry['E14TS200'] + industry['E14TS500']\n\nindustry['SUM'] = industry['E14TS1'] + industry['E14TS6'] + industry['E14TS10'] + industry['E14TS20'] + industry['E14TS50'] + industry['E14TS100'] + industry['E14TS200'] + industry['E14TS500']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.4.4. Merging datasets\n<a id=\"merging_datasets\"></a>"},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"# merging datasets\nfull_dataset = reformatted_salary.merge(geography, how=\"left\", left_on='CODGEO', right_on=\"code_insee\")\nfull_dataset = full_dataset.merge(industry, how=\"left\", on='CODGEO')\n# deleting incomplete rows\nfull_dataset.dropna(inplace = True)\n# selecting relevant columns\nfull_dataset = full_dataset[[\"POSITION\", \"SEX\", \"PARIS_CLOSE\", \"MAJOR_CITY_DISTANCE\", \"MICRO\", \"SMALL\", \"MEDIUM\", \"LARGE\", \"SUM\", \"WAGE\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"colormap = plt.cm.viridis\nplt.figure(figsize=(15,15))\nplt.title('Correlation of Features', y=1.05, size=15)\nsns.heatmap(full_dataset.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> The graph above illustrates the relationship between the successive features of the data set. As expected, the age has the greatest impact on the amount of money earned. The correlation between salary and other characteristics is also perceptible."},{"metadata":{},"cell_type":"markdown","source":"### 2.4.5. Splitting dataset into training and testset\n<a id=\"splitting_dataset_into_training_and_testset\"></a>"},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> First, we need to divide the dataset into matrix of features and vector of values."},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"X = full_dataset.iloc[:, :-1].values\ny = full_dataset.iloc[:, 9].values","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> Finally, we are ready to build a prediction model."},{"metadata":{},"cell_type":"markdown","source":"## 3. Prediction\n<a id=\"prediction\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### 3.1. Linear Regression\n<a id=\"linear_regression\"></a>"},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nregressor_lr = LinearRegression()\nregressor_lr.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred_lr = regressor_lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2. Random Forest Regressor\n<a id=\"random_forest_regressor\"></a>"},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nregressor_rfr = RandomForestRegressor(n_estimators = 10, random_state = 0)\nregressor_rfr.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred_rfr = regressor_rfr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3. Evaluating the regression model\n<a id=\"evaluating_regression_model\"></a>"},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> Definition of the standard error function."},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"def standard_error(y_pred, y_test):\n    sum_value = 0\n    for p, t in zip(y_pred, y_test):\n        sum_value += (p - t)**2\n    \n    return((sum_value/len(y_test))**(1/2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import r2_score\n\nscore_lr = r2_score(y_pred_lr, y_test)\nprint(\"r2 for linear regression is equal \" + str(round(score_lr, 3)))\nscore_rfr = r2_score(y_pred_rfr, y_test)\nprint(\"r2 for random forest regression is equal \" + str(round(score_rfr, 3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"error_lr = standard_error(y_pred_lr.tolist(), y_test.tolist())\nprint(\"standard error for linear regression is equal \" + str(round(error_lr, 3)))\nerror_rfr = standard_error(y_pred_rfr.tolist(), y_test.tolist())\nprint(\"standard error for random forest regression is equal \" + str(round(error_rfr, 3)))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"# To be continued..."},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> At this point, the main task is to test new models and look for even better solutions to our problem."}],"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","version":"3.6.1","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py"}},"nbformat":4,"nbformat_minor":1}